"""
Streamlit Web Application for Face Recognition System
Frontend web interface for collecting, training, and verifying faces
"""

import streamlit as st
import requests
import cv2
import numpy as np
from typing import Dict, Optional, Tuple
import io
from PIL import Image

# Backend URL configuration
BACKEND_URL = "http://localhost:8000"


# ============================================================================
# API Client Functions
# ============================================================================

def call_collect_api(image_bytes: bytes) -> Dict:
    """
    G·ªçi API thu th·∫≠p d·ªØ li·ªáu khu√¥n m·∫∑t.
    
    Args:
        image_bytes: D·ªØ li·ªáu ·∫£nh d·∫°ng bytes
        
    Returns:
        Dict: Response JSON t·ª´ API
        
    Raises:
        requests.exceptions.RequestException: L·ªói khi g·ªçi API
        
    Validates: Requirements 5.3
    """
    try:
        # T·∫°o multipart form data
        files = {
            'file': ('image.jpg', image_bytes, 'image/jpeg')
        }
        
        # G·ªçi POST /api/v1/collect
        response = requests.post(
            f"{BACKEND_URL}/api/v1/collect",
            files=files,
            timeout=30
        )
        
        # Parse JSON response
        response_data = response.json()
        
        # Ki·ªÉm tra status code
        if response.status_code == 200:
            return {
                'success': True,
                'data': response_data
            }
        else:
            # X·ª≠ l√Ω l·ªói t·ª´ backend
            error_detail = response_data.get('detail', 'L·ªói kh√¥ng x√°c ƒë·ªãnh')
            return {
                'success': False,
                'error': error_detail,
                'status_code': response.status_code
            }
            
    except requests.exceptions.RequestException as e:
        return {
            'success': False,
            'error': f"L·ªói k·∫øt n·ªëi ƒë·∫øn backend: {str(e)}",
            'status_code': None
        }


def call_train_api() -> Dict:
    """
    G·ªçi API hu·∫•n luy·ªán m√¥ h√¨nh.
    
    Returns:
        Dict: Response JSON t·ª´ API
        
    Raises:
        requests.exceptions.RequestException: L·ªói khi g·ªçi API
        
    Validates: Requirements 5.5
    """
    try:
        # G·ªçi POST /api/v1/train
        response = requests.post(
            f"{BACKEND_URL}/api/v1/train",
            timeout=60  # Training c√≥ th·ªÉ m·∫•t nhi·ªÅu th·ªùi gian h∆°n
        )
        
        # Parse JSON response
        response_data = response.json()
        
        # Ki·ªÉm tra status code
        if response.status_code == 200:
            return {
                'success': True,
                'data': response_data
            }
        else:
            # X·ª≠ l√Ω l·ªói t·ª´ backend
            error_detail = response_data.get('detail', 'L·ªói kh√¥ng x√°c ƒë·ªãnh')
            return {
                'success': False,
                'error': error_detail,
                'status_code': response.status_code
            }
            
    except requests.exceptions.RequestException as e:
        return {
            'success': False,
            'error': f"L·ªói k·∫øt n·ªëi ƒë·∫øn backend: {str(e)}",
            'status_code': None
        }


def call_verify_api(image_bytes: bytes, threshold: float) -> Dict:
    """
    G·ªçi API nh·∫≠n di·ªán khu√¥n m·∫∑t.
    
    Args:
        image_bytes: D·ªØ li·ªáu ·∫£nh d·∫°ng bytes
        threshold: Ng∆∞·ª°ng so s√°nh (0.0 - 1.0)
        
    Returns:
        Dict: Response JSON t·ª´ API
        
    Raises:
        requests.exceptions.RequestException: L·ªói khi g·ªçi API
        
    Validates: Requirements 5.7
    """
    try:
        # T·∫°o multipart form data
        files = {
            'file': ('image.jpg', image_bytes, 'image/jpeg')
        }
        
        # T·∫°o query parameters
        params = {
            'threshold': threshold
        }
        
        # G·ªçi POST /api/v1/face/verify
        response = requests.post(
            f"{BACKEND_URL}/api/v1/face/verify",
            files=files,
            params=params,
            timeout=30
        )
        
        # Parse JSON response
        response_data = response.json()
        
        # Ki·ªÉm tra status code
        if response.status_code == 200:
            return {
                'success': True,
                'data': response_data
            }
        else:
            # X·ª≠ l√Ω l·ªói t·ª´ backend
            error_detail = response_data.get('detail', 'L·ªói kh√¥ng x√°c ƒë·ªãnh')
            return {
                'success': False,
                'error': error_detail,
                'status_code': response.status_code
            }
            
    except requests.exceptions.RequestException as e:
        return {
            'success': False,
            'error': f"L·ªói k·∫øt n·ªëi ƒë·∫øn backend: {str(e)}",
            'status_code': None
        }


# ============================================================================
# Image Processing Functions
# ============================================================================

def draw_box(image_bgr: np.ndarray, face_box: Dict, is_match: bool) -> np.ndarray:
    """
    V·∫Ω bounding box l√™n ·∫£nh.
    
    Args:
        image_bgr: ·∫¢nh BGR t·ª´ OpenCV
        face_box: Dictionary ch·ª©a top, right, bottom, left
        is_match: True n·∫øu kh·ªõp (m√†u xanh), False n·∫øu kh√¥ng kh·ªõp (m√†u ƒë·ªè)
        
    Returns:
        np.ndarray: ·∫¢nh ƒë√£ v·∫Ω bounding box
        
    Validates: Requirements 5.8
    """
    # Copy ·∫£nh ƒë·ªÉ kh√¥ng thay ƒë·ªïi ·∫£nh g·ªëc
    image_with_box = image_bgr.copy()
    
    # L·∫•y t·ªça ƒë·ªô
    top = face_box['top']
    right = face_box['right']
    bottom = face_box['bottom']
    left = face_box['left']
    
    # Ch·ªçn m√†u: xanh l√° n·∫øu kh·ªõp, ƒë·ªè n·∫øu kh√¥ng kh·ªõp
    # OpenCV s·ª≠ d·ª•ng BGR format
    if is_match:
        color = (0, 255, 0)  # Xanh l√° (Green)
        label = "MATCH"
    else:
        color = (0, 0, 255)  # ƒê·ªè (Red)
        label = "NO MATCH"
    
    # V·∫Ω rectangle
    cv2.rectangle(
        image_with_box,
        (left, top),
        (right, bottom),
        color,
        2  # ƒê·ªô d√†y c·ªßa ƒë∆∞·ªùng vi·ªÅn
    )
    
    # V·∫Ω label
    # T·∫°o background cho text
    cv2.rectangle(
        image_with_box,
        (left, top - 30),
        (right, top),
        color,
        -1  # Fill
    )
    
    # V·∫Ω text
    cv2.putText(
        image_with_box,
        label,
        (left + 6, top - 6),
        cv2.FONT_HERSHEY_SIMPLEX,
        0.8,
        (255, 255, 255),  # M√†u tr·∫Øng
        2
    )
    
    return image_with_box


def capture_frame_from_webcam() -> Optional[np.ndarray]:
    """
    Ch·ª•p m·ªôt frame t·ª´ webcam.
    
    Returns:
        Optional[np.ndarray]: ·∫¢nh BGR t·ª´ webcam, ho·∫∑c None n·∫øu l·ªói
        
    Validates: Requirements 5.8
    """
    try:
        # M·ªü webcam (device 0)
        cap = cv2.VideoCapture(0)
        
        if not cap.isOpened():
            st.error("Kh√¥ng th·ªÉ m·ªü webcam. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi.")
            return None
        
        # ƒê·ªçc m·ªôt frame
        ret, frame = cap.read()
        
        # Gi·∫£i ph√≥ng webcam
        cap.release()
        
        if not ret:
            st.error("Kh√¥ng th·ªÉ ƒë·ªçc frame t·ª´ webcam.")
            return None
        
        return frame
        
    except Exception as e:
        st.error(f"L·ªói khi ch·ª•p t·ª´ webcam: {str(e)}")
        return None


# ============================================================================
# Helper Functions
# ============================================================================

def convert_pil_to_bytes(pil_image: Image.Image) -> bytes:
    """
    Chuy·ªÉn ƒë·ªïi PIL Image th√†nh bytes.
    
    Args:
        pil_image: PIL Image object
        
    Returns:
        bytes: D·ªØ li·ªáu ·∫£nh d·∫°ng bytes (JPEG format)
    """
    img_byte_arr = io.BytesIO()
    pil_image.save(img_byte_arr, format='JPEG')
    img_byte_arr.seek(0)
    return img_byte_arr.read()


def convert_bgr_to_rgb(image_bgr: np.ndarray) -> np.ndarray:
    """
    Chuy·ªÉn ƒë·ªïi ·∫£nh t·ª´ BGR sang RGB.
    
    Args:
        image_bgr: ·∫¢nh BGR t·ª´ OpenCV
        
    Returns:
        np.ndarray: ·∫¢nh RGB
    """
    return cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)


def display_environment_info(env_info: Dict):
    """
    Hi·ªÉn th·ªã th√¥ng tin m√¥i tr∆∞·ªùng.
    
    Args:
        env_info: Dictionary ch·ª©a th√¥ng tin m√¥i tr∆∞·ªùng
    """
    st.subheader("üìä Th√¥ng tin m√¥i tr∆∞·ªùng")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ƒê·ªô s√°ng", f"{env_info['brightness']:.1f}")
        if env_info['is_too_dark']:
            st.warning("‚ö†Ô∏è Qu√° t·ªëi")
        elif env_info['is_too_bright']:
            st.warning("‚ö†Ô∏è Qu√° s√°ng")
        else:
            st.success("‚úÖ T·ªët")
    
    with col2:
        st.metric("ƒê·ªô m·ªù", f"{env_info['blur_score']:.1f}")
        if env_info['is_too_blurry']:
            st.warning("‚ö†Ô∏è Qu√° m·ªù")
        else:
            st.success("‚úÖ T·ªët")
    
    with col3:
        st.metric("T·ª∑ l·ªá khu√¥n m·∫∑t", f"{env_info['face_size_ratio']:.2%}")
        if env_info['is_face_too_small']:
            st.warning("‚ö†Ô∏è Qu√° nh·ªè")
        else:
            st.success("‚úÖ T·ªët")
    
    # Hi·ªÉn th·ªã warnings n·∫øu c√≥
    if env_info['warnings']:
        st.warning("**C·∫£nh b√°o:**")
        for warning in env_info['warnings']:
            st.write(f"- {warning}")


# ============================================================================
# Main Application
# ============================================================================

def main():
    """
    Main function for Streamlit web application.
    """
    # C·∫•u h√¨nh trang
    st.set_page_config(
        page_title="Face Recognition System",
        page_icon="üë§",
        layout="wide"
    )
    
    st.title("üë§ H·ªá th·ªëng Nh·∫≠n di·ªán Khu√¥n m·∫∑t")
    st.markdown("---")
    
    # T·∫°o tabs
    tab1, tab2, tab3 = st.tabs([
        "üì∏ Thu th·∫≠p d·ªØ li·ªáu",
        "üéì Hu·∫•n luy·ªán m√¥ h√¨nh",
        "üîç Nh·∫≠n di·ªán khu√¥n m·∫∑t"
    ])
    
    # Tab 1: Thu th·∫≠p d·ªØ li·ªáu
    with tab1:
        st.header("üì∏ Thu th·∫≠p d·ªØ li·ªáu khu√¥n m·∫∑t")
        st.write("Upload ·∫£nh ho·∫∑c ch·ª•p t·ª´ webcam ƒë·ªÉ thu th·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán.")
        
        # Ch·ªçn ph∆∞∆°ng th·ª©c
        method = st.radio(
            "Ch·ªçn ph∆∞∆°ng th·ª©c:",
            ["Upload ·∫£nh t·ª´ m√°y", "Ch·ª•p t·ª´ webcam"],
            key="collect_method"
        )
        
        image_bytes = None
        
        if method == "Upload ·∫£nh t·ª´ m√°y":
            uploaded_file = st.file_uploader(
                "Ch·ªçn ·∫£nh khu√¥n m·∫∑t",
                type=['jpg', 'jpeg', 'png'],
                key="collect_upload"
            )
            
            if uploaded_file is not None:
                image_bytes = uploaded_file.read()
                st.image(image_bytes, caption="·∫¢nh ƒë√£ ch·ªçn", use_column_width=True)
        
        else:  # Ch·ª•p t·ª´ webcam
            if st.button("üì∑ Ch·ª•p ·∫£nh t·ª´ webcam", key="collect_capture"):
                with st.spinner("ƒêang ch·ª•p ·∫£nh..."):
                    frame = capture_frame_from_webcam()
                    
                    if frame is not None:
                        # Chuy·ªÉn BGR sang RGB ƒë·ªÉ hi·ªÉn th·ªã
                        frame_rgb = convert_bgr_to_rgb(frame)
                        st.image(frame_rgb, caption="·∫¢nh ƒë√£ ch·ª•p", use_column_width=True)
                        
                        # Chuy·ªÉn th√†nh bytes
                        _, buffer = cv2.imencode('.jpg', frame)
                        image_bytes = buffer.tobytes()
        
        # N√∫t g·ª≠i
        if image_bytes is not None:
            if st.button("‚úÖ G·ª≠i ·∫£nh ƒë·ªÉ thu th·∫≠p", key="collect_submit"):
                with st.spinner("ƒêang x·ª≠ l√Ω..."):
                    result = call_collect_api(image_bytes)
                    
                    if result['success']:
                        data = result['data']
                        st.success(data['message'])
                        
                        # Hi·ªÉn th·ªã th√¥ng tin
                        st.info(f"üìÅ ƒê∆∞·ªùng d·∫´n: {data['saved_path']}")
                        st.info(f"üìä T·ªïng s·ªë ·∫£nh ƒë√£ thu th·∫≠p: {data['total_images']}")
                        
                        # Hi·ªÉn th·ªã environment info
                        display_environment_info(data['environment_info'])
                    else:
                        st.error(f"‚ùå L·ªói: {result['error']}")
                        
                        # N·∫øu c√≥ environment_info trong error detail
                        if isinstance(result['error'], dict) and 'environment_info' in result['error']:
                            display_environment_info(result['error']['environment_info'])
    
    # Tab 2: Hu·∫•n luy·ªán m√¥ h√¨nh
    with tab2:
        st.header("üéì Hu·∫•n luy·ªán m√¥ h√¨nh")
        st.write("Hu·∫•n luy·ªán m√¥ h√¨nh nh·∫≠n di·ªán t·ª´ c√°c ·∫£nh ƒë√£ thu th·∫≠p.")
        
        st.info("üí° ƒê·∫£m b·∫£o b·∫°n ƒë√£ thu th·∫≠p √≠t nh·∫•t 5-10 ·∫£nh khu√¥n m·∫∑t tr∆∞·ªõc khi hu·∫•n luy·ªán.")
        
        if st.button("üöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán", key="train_button"):
            with st.spinner("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh... Vui l√≤ng ƒë·ª£i."):
                result = call_train_api()
                
                if result['success']:
                    data = result['data']
                    st.success(data['message'])
                    
                    # Hi·ªÉn th·ªã th√¥ng tin
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("S·ªë ·∫£nh ƒë√£ ƒë·ªçc", data['num_images'])
                    with col2:
                        st.metric("S·ªë embeddings ƒë√£ s·ª≠ d·ª•ng", data['num_embeddings'])
                    
                    st.balloons()
                else:
                    st.error(f"‚ùå L·ªói: {result['error']}")
    
    # Tab 3: Nh·∫≠n di·ªán khu√¥n m·∫∑t
    with tab3:
        st.header("üîç Nh·∫≠n di·ªán khu√¥n m·∫∑t")
        st.write("Upload ·∫£nh ho·∫∑c ch·ª•p t·ª´ webcam ƒë·ªÉ nh·∫≠n di·ªán khu√¥n m·∫∑t.")
        
        # Threshold slider
        threshold = st.slider(
            "Ng∆∞·ª°ng so s√°nh (threshold)",
            min_value=0.0,
            max_value=1.0,
            value=0.5,
            step=0.05,
            help="Ng∆∞·ª°ng c√†ng th·∫•p th√¨ y√™u c·∫ßu c√†ng ch·∫∑t ch·∫Ω"
        )
        
        # Ch·ªçn ph∆∞∆°ng th·ª©c
        method = st.radio(
            "Ch·ªçn ph∆∞∆°ng th·ª©c:",
            ["Upload ·∫£nh t·ª´ m√°y", "Ch·ª•p t·ª´ webcam"],
            key="verify_method"
        )
        
        image_bytes = None
        original_image = None
        
        if method == "Upload ·∫£nh t·ª´ m√°y":
            uploaded_file = st.file_uploader(
                "Ch·ªçn ·∫£nh khu√¥n m·∫∑t",
                type=['jpg', 'jpeg', 'png'],
                key="verify_upload"
            )
            
            if uploaded_file is not None:
                image_bytes = uploaded_file.read()
                original_image = Image.open(io.BytesIO(image_bytes))
                st.image(image_bytes, caption="·∫¢nh ƒë√£ ch·ªçn", use_column_width=True)
        
        else:  # Ch·ª•p t·ª´ webcam
            if st.button("üì∑ Ch·ª•p ·∫£nh t·ª´ webcam", key="verify_capture"):
                with st.spinner("ƒêang ch·ª•p ·∫£nh..."):
                    frame = capture_frame_from_webcam()
                    
                    if frame is not None:
                        # Chuy·ªÉn BGR sang RGB ƒë·ªÉ hi·ªÉn th·ªã
                        frame_rgb = convert_bgr_to_rgb(frame)
                        st.image(frame_rgb, caption="·∫¢nh ƒë√£ ch·ª•p", use_column_width=True)
                        
                        # Chuy·ªÉn th√†nh bytes
                        _, buffer = cv2.imencode('.jpg', frame)
                        image_bytes = buffer.tobytes()
                        
                        # L∆∞u original image
                        original_image = Image.fromarray(frame_rgb)
        
        # N√∫t nh·∫≠n di·ªán
        if image_bytes is not None:
            if st.button("üîç Nh·∫≠n di·ªán khu√¥n m·∫∑t", key="verify_submit"):
                with st.spinner("ƒêang nh·∫≠n di·ªán..."):
                    result = call_verify_api(image_bytes, threshold)
                    
                    if result['success']:
                        data = result['data']
                        
                        # Hi·ªÉn th·ªã k·∫øt qu·∫£
                        if data['is_match']:
                            st.success(f"‚úÖ {data['message']}")
                        else:
                            st.error(f"‚ùå {data['message']}")
                        
                        # Hi·ªÉn th·ªã metrics
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("Kho·∫£ng c√°ch", f"{data['distance']:.3f}")
                        with col2:
                            st.metric("Ng∆∞·ª°ng", f"{data['threshold']:.3f}")
                        
                        # V·∫Ω bounding box l√™n ·∫£nh
                        if original_image is not None:
                            # Chuy·ªÉn PIL sang BGR
                            image_bgr = cv2.cvtColor(
                                np.array(original_image),
                                cv2.COLOR_RGB2BGR
                            )
                            
                            # V·∫Ω box
                            image_with_box = draw_box(
                                image_bgr,
                                data['face_box'],
                                data['is_match']
                            )
                            
                            # Chuy·ªÉn BGR sang RGB ƒë·ªÉ hi·ªÉn th·ªã
                            image_with_box_rgb = convert_bgr_to_rgb(image_with_box)
                            
                            st.image(
                                image_with_box_rgb,
                                caption="K·∫øt qu·∫£ nh·∫≠n di·ªán",
                                use_column_width=True
                            )
                        
                        # Hi·ªÉn th·ªã environment info
                        display_environment_info(data['environment_info'])
                        
                    else:
                        st.error(f"‚ùå L·ªói: {result['error']}")


if __name__ == "__main__":
    main()
